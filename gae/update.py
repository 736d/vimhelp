# Regularly scheduled update: check which files need updating and process them

import os, re, logging, hashlib, base64, json
import webapp2
from google.appengine.api import urlfetch, taskqueue
from google.appengine.ext import ndb
from dbmodel import *
from vimh2h import VimH2H
from google.appengine.api.urlfetch import DownloadError, ResponseTooLargeError

# Once we have consumed about ten minutes of CPU time, Google will throw us a
# DeadlineExceededError and our script terminates. Therefore, we must be careful
# with the order of operations, to ensure that after this has happened, the next
# scheduled run of the script can pick up where the previous one was
# interrupted.

TAGS_NAME = 'tags'
FAQ_NAME = 'vim_faq.txt'
HELP_NAME = 'help.txt'

DOC_ITEM_RE = re.compile(r'(?:[-\w]+\.txt|tags)$')
COMMIT_MSG_RE = re.compile(r'[Pp]atch\s+(\d[^\n]+)')

GITHUB_API_URL_BASE = 'https://api.github.com'
GITHUB_ACCESS_TOKEN = 'cd46dfb1bd21f54c6d17e7bde948a09ad65a074d'

FAQ_BASE_URL = 'https://raw.githubusercontent.com/chrisbra/vim_faq/master/doc/'

# ** Old Google Code specific constants:
# BASE_URL = 'http://vim.googlecode.com/hg/runtime/doc/'
# HGTAGS_URL = 'http://vim.googlecode.com/hg/.hgtags'
# REVISION_RE = re.compile(r'<title>Revision (.+?): /runtime/doc</title>')
# ITEM_RE = re.compile(r'[^-\w]([-\w]+\.txt|tags)[^-\w]')
# HGTAG_RE = re.compile(r'^[0-9A-Fa-f]+ v(\d[\w.-]*)$')

PFD_MAX_PART_LEN = 995000

# Request header name
HTTP_HDR_IF_NONE_MATCH = 'If-None-Match'

# Response header name
HTTP_HDR_ETAG = 'ETag'

# HTTP Status
HTTP_OK = 200
HTTP_NOT_MOD = 304

class UpdateHandler(webapp2.RequestHandler):
    def __init__(self, request, response):
        self.initialize(request, response)

    def post(self):
        # We get an HTTP POST request if the request came programmatically via
        # the Task Queue mechanism.  In that case, we turn off logging.
        return self._run(self.request.body, html_logging=False)

    def get(self):
        # We get an HTTP GET request if the request was generated by the (admin)
        # user, by entering the URL in their browser.  In that case, we turn on
        # logging.
        return self._run(self.request.query_string, html_logging=True)

    def _run(self, query_string, html_logging):
        logger = logging.getLogger()
        debuglog = ('debug' in query_string)
        is_dev = (os.environ.get('SERVER_SOFTWARE', '') \
                  .startswith('Development'))
        if debuglog or is_dev:
            logger.setLevel(logging.DEBUG)
        else:
            logger.setlevel(logging.INFO)

        if html_logging:
            htmlLogHandler = logging.StreamHandler(self.response)
            htmlLogHandler.setFormatter(HtmlLogFormatter())
            logger.addHandler(htmlLogHandler)
            self.response.write("<html><body>")

        try:
            self._update(query_string)
        except:
            logging.exception("exception caught")
            # TODO set bad HTTP status code so the job gets retried?
        finally:
            # it's important we always remove the log handler, otherwise it will
            # be in place for other requests, including to vimhelp.py, where
            # class HtmlLogFormatter won't exist
            if html_logging:
                self.response.write("</body></html>")
                logging.getLogger().removeHandler(htmlLogHandler)

    def _update(self, query_string):
        force = 'force' in query_string

        logging.info("starting %supdate", 'forced ' if force else '')

        if force:
            logging.info("'force' is in effect")
            rfis = RawFileInfo.query().fetch(None)
            for r in rfis:
                r.redo = True
            ndb.put_multi(rfis)
            ndb.Key('GlobalInfo', 'global').delete()
            logging.info("set redo flag on %d item(s)", len(rfis))

        g = GlobalInfo.get_by_id('global') or GlobalInfo(id='global')
        g_changed = False  # track any changes we make to 'g'

        logging.debug("global info: %s",
                      ", ".join("{} = {}".format(n, getattr(g, n)) for n in
                                g._properties.iterkeys()))

        g_changed = self._do_update(g)

        if g_changed:
            logging.info("finished update, writing global info")
            g.put()
        else:
            logging.info("finished update, global info unchanged")

    @ndb.toplevel
    def _do_update(self, g):
        g_changed = False

        # Kick off retrieval of all RawFileInfo entities from the Datastore

        all_rfi_future = RawFileInfo.query().fetch_async()

        # Kick off retrieval of data about latest commit on master branch, which
        # we will use to figure out if there is a new vim version

        master_future = async_vim_github_request(
            '/repos/vim/vim/branches/master', g.master_etag)

        # Kick off retrieval of 'runtime/doc' dir listing in github

        docdir_future = async_vim_github_request(
            '/repos/vim/vim/contents/runtime/doc', g.docdir_etag)

        # Put all RawFileInfo entites into a map

        rfi_map = { r.key.string_id(): r for r in all_rfi_future.get_result() }

        urlfetch_futures = set()
        urlfetch_futures_by_name = {}

        def queue_urlfetch(name, url):
            rfi = rfi_map.get(name)
            etag = rfi.etag if rfi is not None else None
            logging.debug("fetching %s (etag: %s)", name, etag)
            uf_future = async_urlfetch(url, etag, user_context=name)
            urlfetch_futures.add(uf_future)
            urlfetch_futures_by_name[name] = uf_future

        # Kick off FAQ download

        queue_urlfetch(FAQ_NAME, FAQ_BASE_URL + FAQ_NAME)

        # Iterating over 'runtime/doc' dir listing, kick off download for all
        # modified items

        docdir = docdir_future.get_result()

        if docdir.status_code == HTTP_NOT_MOD:
            logging.info("doc dir not modified")
        elif docdir.status_code == HTTP_OK:
            g.docdir_etag = docdir.headers.get(HTTP_HDR_ETAG)
            g_changed = True
            logging.debug("got doc dir etag %s (%s)", g.docdir_etag)
            for item in docdir.json:
                name = item['name'].encode()
                if item['type'] == 'file' and DOC_ITEM_RE.match(name):
                    assert name not in urlfetch_futures_by_name
                    rfi = rfi_map.get(name)
                    if rfi is not None and rfi.sha == item['sha']:
                        logging.debug("%s unchanged (sha=%s)", name, rfi.sha)
                        continue
                    queue_urlfetch(name, item['download_url'])

        # Check if the Vim version has changed; we display it on our front page,
        # so we must keep it updated even if nothing else has changed

        is_new_vim_version = False

        master = master_future.get_result()

        if master.status_code == HTTP_OK:
            message = master.json['commit']['commit']['message'].encode()
            m = COMMIT_MSG_RE.match(message)
            if m:
                new_vim_version = m.group(1)
                if new_vim_version != g.vim_version:
                    logging.info("found new vim version %s (was: %s)",
                                 new_vim_version, g.vim_version)
                    is_new_vim_version = True
                    g.vim_version = new_vim_version
                    g_changed = True
                else:
                    logging.warn("master branch has moved forward, but vim "
                                 "version from commit message is unchanged: "
                                 "'%s' -> version '%s'", message, g.vim_version)
            else:
                logging.warn("master branch has moved forward, but no new vim "
                             "version found in commit msg ('%s'), so keeping "
                             "old one (%s)", message, g.vim_version)
            g.master_etag = master.headers.get(HTTP_HDR_ETAG)
            g_changed = True
        elif g.master_etag and master.status_code == HTTP_NOT_MOD:
            logging.info("master branch is unchanged, so no new vim version")
        else:
            logging.warn("failed to get master branch: HTTP status %d",
                         master.status_code)

        # If there is no new vim version, and if the only file we're downloading
        # is the FAQ, and if the FAQ was not modified, then there is nothing to
        # do for us, so bail out now

        if not is_new_vim_version and len(urlfetch_futures) == 1:
            faq_uf = urlfetch_futures_by_name[FAQ_NAME].get_result()
            if faq_uf.status_code == HTTP_NOT_MOD:
                return g_changed

        def async_get_contents(name):
            uf = urlfetch_futures.get(name)
            if uf is not None:
                return HttpFetch(uf)
            else:
                return DbFetch(name)

        # Make sure we are retrieving tags, either from HTTP or from Datastore
        tags_future = async_get_contents(TAGS_NAME)

        # Make sure we are retrieving FAQ, either from HTTP or from Datastore
        faq_future = async_get_contents(FAQ_NAME)

        # If we found a new vim version and we're not already downloading
        # help.txt, kick off its retrieval from the Datastore instead
        # (since we're displaying the current vim version in the rendered
        # help.txt.html)
        help_future = None
        if is_new_vim_version and HELP_NAME not in urlfetch_futures_by_name:
            help_future = DbFetch(HELP_NAME)

        # Construct the vimhelp-to-html converter, providing it the tags file,
        # and adding on the FAQ for extra tags
        h2h = VimH2H(tags_future.content, g.vim_version)
        h2h.add_tags(FAQ_NAME, faq_future.get_result())

        # ... TODO ...

        # Wait for urlfetches to return

        while len(urlfetch_futures) > 0:
            future = ndb.Future.wait_any(urlfetch_futures)
            result, name = future.get_result()
            logging.info("got status code %s for %s", result.status_code, name)
            process_async(name, result, h2h)
            urlfetch_futures.remove(future)
            del urlfetch_futures_by_name[name]

        return g_changed


class EnqueueUpdateHandler(webapp2.RequestHandler):
    def get(self):
        logging.info("enqueueing update")
        taskqueue.add(queue_name='update', url='/update',
                      payload=self.request.query_string)

class VimhelpError(Exception):
    def __init__(self, msg, *args):
        self.msg = msg
        self.args = args

    def __str__(self):
        return self.msg % args

class HtmlLogFormatter(logging.Formatter):
    def format(self, record):
        fmsg = super(HtmlLogFormatter, self).format(record). \
                replace('&', '&amp;'). \
                replace('<', '&lt;').replace('>', '&gt;'). \
                replace(' ', '&nbsp;<wbr/>').replace('\n', '<br/>')
        if record.levelno >= logging.ERROR:
            fmsg = 'ERROR: ' + fmsg
        if record.levelno >= logging.WARNING:
            return '<p><b>' + fmsg + '</b></p>'
        elif record.levelno >= logging.INFO:
            return '<p>' + fmsg + '</p>'
        else:
            return '<p style="color: gray">' + fmsg + '</p>'


def async_vim_github_request(document, etag):
    headers = {
        'Accept':        'application/vnd.github.v3+json',
        'Authorization': 'token ' + GITHUB_ACCESS_TOKEN,
    }
    return async_urlfetch(GITHUB_API_URL_BASE + document, etag, is_json=True,
                          headers=headers)

@ndb.tasklet
def async_urlfetch(url, etag, is_json=False, headers=None, user_context=None):
    all_headers = { }
    if headers is not None:
        all_headers.update(headers)
    if etag is not None:
        all_headers[HTTP_HDR_IF_NONE_MATCH] = etag
    logging.debug("requesting url '%s', headers = %s", url, headers)
    ctx = ndb.get_context()
    result = yield ctx.urlfetch(url, headers)
    logging.debug("response status for url %s is %s", url, result.status_code)
    if result.status_code == HTTP_OK and is_json:
        result.json = json.loads(result.content)
    if user_context is not None:
        raise ndb.Return((result, user_context))
    else:
        raise ndb.Return(result)


app = webapp2.WSGIApplication([
    ('/update', UpdateHandler),
    ('/enqueue_update', EnqueueUpdateHandler)
])
